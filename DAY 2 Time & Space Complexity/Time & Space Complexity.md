# Time & Space Complexity

Understanding **Time Complexity** and **Space Complexity** is essential for writing efficient algorithms.  
They help us measure how an algorithm performs as the input size grows.

---

## â±ï¸ Time Complexity

**Time Complexity** measures the efficiency of an algorithm in terms of **execution time** as the input size (`n`) increases.

 **Lower Time Complexity = Faster Algorithm**

It describes how the running time of an algorithm grows with respect to input size.

---

### Common Time Complexities

| Notation | Meaning | Example |
|--------|--------|--------|
| **O(1)** | Constant time â€“ independent of input size | Accessing an array element |
| **O(log n)** | Logarithmic â€“ input is halved each step | Binary Search |
| **O(n)** | Linear â€“ grows directly with input size | Looping through an array |
| **O(n log n)** | Linearithmic â€“ common in efficient sorting | Merge Sort, Quick Sort |
| **O(nÂ²)** | Quadratic â€“ nested loops | Bubble Sort, Selection Sort |
| **O(2â¿)** | Exponential â€“ doubles with each input | Recursive Fibonacci |
| **O(n!)** | Factorial â€“ all possible permutations | Traveling Salesman Problem |

---

## ğŸ’¾ Space Complexity

**Space Complexity** measures how much **extra memory** an algorithm requires relative to the input size.

It includes:
- Variables
- Data structures
- Recursive call stack

---

## Common Space Complexities

| Notation | Meaning |
|--------|--------|
| **O(1)** | Constant space â€“ memory usage does not grow |
| **O(n)** | Linear space â€“ memory grows with input |
| **O(nÂ²)** | Quadratic space â€“ used in 2D arrays or matrices |

---

## ğŸ“Œ Key Takeaways

- Time Complexity focuses on **speed**
- Space Complexity focuses on **memory**
- Efficient algorithms balance **both**
- Big-O notation represents the **worst-case scenario**


## ğŸš€ Happy Coding!


