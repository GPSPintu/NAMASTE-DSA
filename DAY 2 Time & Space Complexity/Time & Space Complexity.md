# Time & Space Complexity

Understanding **Time Complexity** and **Space Complexity** is essential for writing efficient algorithms.  
They help us measure how an algorithm performs as the input size grows.

---

## ‚è±Ô∏è Time Complexity

**Time Complexity** measures the efficiency of an algorithm in terms of **execution time** as the input size (`n`) increases.

 **Lower Time Complexity = Faster Algorithm**

It describes how the running time of an algorithm grows with respect to input size.

---

### Common Time Complexities

| Notation | Meaning | Example |
|--------|--------|--------|
| **O(1)** | Constant time ‚Äì independent of input size | Accessing an array element |
| **O(log n)** | Logarithmic ‚Äì input is halved each step | Binary Search |
| **O(n)** | Linear ‚Äì grows directly with input size | Looping through an array |
| **O(n log n)** | Linearithmic ‚Äì common in efficient sorting | Merge Sort, Quick Sort |
| **O(n¬≤)** | Quadratic ‚Äì nested loops | Bubble Sort, Selection Sort |
| **O(2‚Åø)** | Exponential ‚Äì doubles with each input | Recursive Fibonacci |
| **O(n!)** | Factorial ‚Äì all possible permutations | Traveling Salesman Problem |

---

## üíæ Space Complexity

**Space Complexity** measures how much **extra memory** an algorithm requires relative to the input size.

It includes:
- Variables
- Data structures
- Recursive call stack

---

## Common Space Complexities

| Notation | Meaning |
|--------|--------|
| **O(1)** | Constant space ‚Äì memory usage does not grow |
| **O(n)** | Linear space ‚Äì memory grows with input |
| **O(n¬≤)** | Quadratic space ‚Äì used in 2D arrays or matrices |

---

üìå Key Takeaways

- Time Complexity focuses on **speed**
- Space Complexity focuses on **memory**
- Efficient algorithms balance **both**
- Big-O notation represents the **worst-case scenario**





